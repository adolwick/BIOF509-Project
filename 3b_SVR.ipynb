{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3b. Support Vector Regressor\n",
    "\n",
    "We can now load either our PCA data or our UMAP data and use supervised learning algorithms to predict our outcome variable using the scaled and reduced data. I have created two separate files for this step, differing on which algorithm they use (Random Forest Regressor vs. Support Vector Regressor). These are designed to work completely separate from one another, and only running one of the two is necessary, but it is helpful to run both and compare them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVregressor:\n",
    "    \n",
    "    '''\n",
    "        INIT FUNCTION:\n",
    "        \n",
    "        -- This __init__ function is slightly different from the ones used in KNN Imputation, PCA, and UMAP.\n",
    "        \n",
    "        -- In addition to specifying \"IDs\", specify an outcome variable to predict. \"IDs\" should still include this variable.\n",
    "        \n",
    "        -- self.X is an array containing all the data except the IDs; self.y is an array of the values of the outcome variable.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, datafile, outcome, IDs = []):\n",
    "        self.df = pd.read_csv(datafile)\n",
    "        self.X = np.array(self.df.drop(IDs, 1))\n",
    "        self.y = np.array(self.df[outcome])\n",
    "        self.Xdf = pd.DataFrame(self.X)\n",
    "        self.ydf = pd.DataFrame(self.y)\n",
    "        \n",
    "    '''\n",
    "        REGRESS METHOD:\n",
    "        \n",
    "        --Specify a kernel, a scoring method, and a number of folds for cross-validation.\n",
    "        \n",
    "        --self.predictions outputs predicted values; self-scores outputs specified metrics of model performance.\n",
    "    '''    \n",
    "    \n",
    "    def regress(self, kernel, scoring, cv=[]):\n",
    "        self.svr_model = SVR(kernel=kernel)\n",
    "        self.predictions = cross_val_predict(self.svr_model, self.X, self.y, cv=cv)\n",
    "        self.scores = cross_val_score(self.svr_model, self.X, self.y, cv=cv, scoring=scoring)\n",
    "        print(self.scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear kernel\n",
    "#Inputting PCA data for this example\n",
    "#Outcome variable is presence, IDs are presence and labvisitid\n",
    "linear = SVregressor(\"SCALED_PCA_DATA.csv\", 'presence', IDs = ['labvisitid', 'presence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.57381543 -0.87892184 -0.5007123  -0.67230961 -0.58374557]\n"
     ]
    }
   ],
   "source": [
    "#Outputting (negative) mean squared error\n",
    "#For some reason, sklearn outputs negative values for mean squared error and some related metrics,...\n",
    "#...so they changed the name to 'neg_mean_squared_error'\n",
    "linear.regress('linear','neg_mean_squared_error', cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RBF kernel\n",
    "rbf = SVregressor(\"SCALED_PCA_DATA.csv\", 'presence', IDs = ['labvisitid', 'presence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.62976218 -0.69928623 -0.49504079 -0.55943645 -0.56887076]\n"
     ]
    }
   ],
   "source": [
    "#Outputting (negative) mean squared error\n",
    "rbf.regress('rbf', 'neg_mean_squared_error', cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear: [-0.57381543 -0.87892184 -0.5007123  -0.67230961 -0.58374557]\n",
      "RBF: [-0.62976218 -0.69928623 -0.49504079 -0.55943645 -0.56887076]\n"
     ]
    }
   ],
   "source": [
    "#Comparing scores of (negative) mean squared error from both kernels\n",
    "#The RBF kernel performs better on average\n",
    "print(\"Linear:\", linear.scores)\n",
    "print(\"RBF:\", rbf.scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
